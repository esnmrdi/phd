{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Training temporally aggregated ARIMA models for FCR estimation to compare its performance with our vehicle-specific metamodels at low-res scales\r\n",
    "#### Ehsan Moradi, Ph.D. Candidate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Load required libraries\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "from statsmodels.tsa.arima.model import ARIMA\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.metrics import r2_score\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# General settings\r\n",
    "VEHICLES = (\r\n",
    "    \"019 Hyundai Elantra GT 2019 (2.0L Auto)\",\r\n",
    "    \"025 Chevrolet Captiva 2010 (2.4L Auto)\",\r\n",
    "    \"027 Chevrolet Cruze 2011 (1.8L Manual)\",\r\n",
    ")\r\n",
    "FEATURES = [\"SPD_KH\", \"ACC_MS2\", \"ALT_M\"]\r\n",
    "DEPENDENT = \"FCR_LH\"\r\n",
    "SETTINGS = {\r\n",
    "    \"INPUT_TYPE\": \"ENSEMBLE\",\r\n",
    "    \"INPUT_INDEX\": \"06\",\r\n",
    "    \"OUTPUT_TYPE\": \"ARIMA\",\r\n",
    "    \"OUTPUT_INDEX\": \"AGGREGATE\",\r\n",
    "}\r\n",
    "AGG_CFG = {\"DATETIME\": \"last\", \"ALT_M\": \"mean\", \"SPD_KH\": \"mean\",\r\n",
    "           \"FCR_LH\": \"mean\", \"ACC_MS2\": \"mean\", \"FCR_LH_PRED_METAMODEL\": \"mean\"}\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# Load sample data from Excel to a pandas dataframe\r\n",
    "def load_from_Excel(vehicle, sheet, settings):\r\n",
    "    directory = (\r\n",
    "        \"../../Academia/PhD/Field Experiments/Veepeak/\"\r\n",
    "        + vehicle\r\n",
    "        + \"/Processed/\"\r\n",
    "        + settings[\"INPUT_TYPE\"]\r\n",
    "        + \"/\"\r\n",
    "    )\r\n",
    "    input_file = vehicle + \" - {0} - {1}.xlsx\".format(\r\n",
    "        settings[\"INPUT_TYPE\"], settings[\"INPUT_INDEX\"]\r\n",
    "    )\r\n",
    "    input_path = directory + input_file\r\n",
    "    df = pd.read_excel(input_path, sheet_name=sheet, header=0)\r\n",
    "    return df\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Save the predicted field back to Excel file\r\n",
    "def save_to_excel(df, vehicle, scale, settings):\r\n",
    "    directory = (\r\n",
    "        \"../../Academia/PhD/Field Experiments/Veepeak/\"\r\n",
    "        + vehicle\r\n",
    "        + \"/Processed/\"\r\n",
    "        + settings[\"OUTPUT_TYPE\"]\r\n",
    "        + \"/\"\r\n",
    "    )\r\n",
    "    output_file = vehicle + \" - {0} - {1} - {2}-SEC.xlsx\".format(\r\n",
    "        settings[\"OUTPUT_TYPE\"], settings[\"OUTPUT_INDEX\"], scale\r\n",
    "    )\r\n",
    "    output_path = directory + output_file\r\n",
    "    with pd.ExcelWriter(output_path, engine=\"openpyxl\", mode=\"w\") as writer:\r\n",
    "        df.to_excel(writer, header=True, index=None)\r\n",
    "    print(\"{} -> Data is saved to Excel successfully!\".format(vehicle))\r\n",
    "    return None\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Training the ARIMA model for three temporal scales (1-sec, 5-sec, and 10-sec)\r\n",
    "# and generating out-of-sample predictions\r\n",
    "predictions, observations = {}, {}\r\n",
    "for vehicle in VEHICLES:\r\n",
    "    predictions[vehicle], observations[vehicle] = {}, {}\r\n",
    "    df = load_from_Excel(vehicle, \"Sheet1\", SETTINGS)\r\n",
    "    df = df[[\"DATETIME\", \"ALT_M\", \"SPD_KH\", \"FCR_LH\",\r\n",
    "             \"ACC_MS2\", \"FCR_LH_PRED_METAMODEL\"]]\r\n",
    "    for scale in [1, 5, 10]:\r\n",
    "        dfs = df.groupby(df.index // scale).agg(AGG_CFG)\r\n",
    "        # Apply feature scaling\r\n",
    "        scaler_features = StandardScaler().fit(dfs[FEATURES])\r\n",
    "        scaler_dependent = StandardScaler().fit(dfs[[DEPENDENT]])\r\n",
    "        dfs[FEATURES] = scaler_features.transform(dfs[FEATURES])\r\n",
    "        dfs[[DEPENDENT]] = scaler_dependent.transform(dfs[[DEPENDENT]])\r\n",
    "        # Train-Test splitting (70%-30%)\r\n",
    "        split_point = int(.7 * len(dfs))\r\n",
    "        train = dfs[:split_point].copy(deep=True)\r\n",
    "        # Train the ARIMA model\r\n",
    "        # The AR order is chosen as 6 (in accordance with our RNN modeling lag order)\r\n",
    "        # As the variables could be considered stationary (they are bounded and trendless), \"difference\" is set to 0.\r\n",
    "        # Moving-average order of 3 is applied.\r\n",
    "        model_l6 = ARIMA(train[DEPENDENT],\r\n",
    "                         exog=train[FEATURES], order=(6, 0, 3))\r\n",
    "        fit_l6 = model_l6.fit(method_kwargs={\"warn_convergence\": False})\r\n",
    "        # Out-of-sample prediction\r\n",
    "        predictions[vehicle][scale] = fit_l6.predict(\r\n",
    "            start=len(train), end=len(dfs) - 1, exog=dfs[FEATURES][split_point:]).values\r\n",
    "        # Apply inverse scaling\r\n",
    "        dfs[FEATURES] = scaler_features.inverse_transform(dfs[FEATURES])\r\n",
    "        predictions[vehicle][scale] = scaler_dependent.inverse_transform(\r\n",
    "            predictions[vehicle][scale])\r\n",
    "        dfs[[DEPENDENT]] = scaler_dependent.inverse_transform(\r\n",
    "            dfs[[DEPENDENT]])\r\n",
    "        observations[vehicle][scale] = dfs[DEPENDENT][split_point:]\r\n",
    "        dfs.loc[split_point:, \"FCR_LH_PRED_ARIMA_{0}_SEC\".format(\r\n",
    "            scale)] = predictions[vehicle][scale]\r\n",
    "        save_to_excel(dfs, vehicle, scale, SETTINGS)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Time-series plot of ARIMA predictions vs. true observations for a selected time-window\r\n",
    "for vehicle in VEHICLES:\r\n",
    "    for scale in [1, 5, 10]:\r\n",
    "        fig, ax = plt.subplots(figsize=(12, 4))\r\n",
    "        sns.lineplot(x=range(750), y=predictions[vehicle][scale][0:750], color=\"blue\")\r\n",
    "        sns.lineplot(x=range(750), y=observations[vehicle][scale][0:750], color=\"red\")\r\n",
    "        plt.legend(labels=[\"Predictions (AR Order = 6)\", \"True Observations\"])\r\n",
    "        plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Scatter plot to compare ARIMA predictions and true observations\r\n",
    "for vehicle in VEHICLES:\r\n",
    "    for scale in [1, 5, 10]:\r\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\r\n",
    "        sns.scatterplot(x=observations[vehicle][scale], y=predictions[vehicle][scale])\r\n",
    "        upper_bound = np.max([np.max(observations[vehicle][scale]),\r\n",
    "                            np.max(predictions[vehicle][scale])])\r\n",
    "        plt.xlim(0, upper_bound)\r\n",
    "        plt.ylim(0, upper_bound)\r\n",
    "        plt.xlabel(\"True Observations\")\r\n",
    "        plt.ylabel(\"ARIMA Predictions (AR Order = 6)\")\r\n",
    "        plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Calculate R-squared score of scaled ARIMA models\r\n",
    "for vehicle in VEHICLES:\r\n",
    "    for scale in [1, 5, 10]:\r\n",
    "        print(\"{0}, {1}: {2}\".format(vehicle, scale, r2_score(\r\n",
    "            observations[vehicle][scale], predictions[vehicle][scale])))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "019 Hyundai Elantra GT 2019 (2.0L Auto), 1: 0.5256432994136848\n",
      "019 Hyundai Elantra GT 2019 (2.0L Auto), 5: 0.6599507495708109\n",
      "019 Hyundai Elantra GT 2019 (2.0L Auto), 10: 0.7143308152151611\n",
      "025 Chevrolet Captiva 2010 (2.4L Auto), 1: 0.10790025568393047\n",
      "025 Chevrolet Captiva 2010 (2.4L Auto), 5: 0.24965064042552265\n",
      "025 Chevrolet Captiva 2010 (2.4L Auto), 10: 0.22913369857489152\n",
      "027 Chevrolet Cruze 2011 (1.8L Manual), 1: 0.5548563597332341\n",
      "027 Chevrolet Cruze 2011 (1.8L Manual), 5: 0.6666841247201505\n",
      "027 Chevrolet Cruze 2011 (1.8L Manual), 10: 0.703432450942992\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# Load sample data from Excel to a pandas dataframe (for scaled predictions)\r\n",
    "def load_from_Excel_scaled(vehicle, scale, sheet):\r\n",
    "    directory = (\r\n",
    "        \"../../Academia/PhD/Field Experiments/Veepeak/\"\r\n",
    "        + vehicle\r\n",
    "        + \"/Processed/ARIMA/\"\r\n",
    "    )\r\n",
    "    input_file = vehicle + \" - ARIMA - AGGREGATE - {0}-SEC.xlsx\".format(scale)\r\n",
    "    input_path = directory + input_file\r\n",
    "    df = pd.read_excel(input_path, sheet_name=sheet, header=0)\r\n",
    "    return df\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Calculate R-square score for scaled metamodel predictions\r\n",
    "for vehicle in VEHICLES:\r\n",
    "    for scale in [1, 5, 10]:\r\n",
    "        df = load_from_Excel_scaled(vehicle, scale, \"Sheet1\")\r\n",
    "        print(\"{0}, {1}: {2}\".format(vehicle, scale, r2_score(\r\n",
    "            df[\"FCR_LH\"], df[\"FCR_LH_PRED_METAMODEL\"])))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "019 Hyundai Elantra GT 2019 (2.0L Auto), 1: 0.7179144438996059\n",
      "019 Hyundai Elantra GT 2019 (2.0L Auto), 5: 0.827947997358645\n",
      "019 Hyundai Elantra GT 2019 (2.0L Auto), 10: 0.8397226533437434\n",
      "025 Chevrolet Captiva 2010 (2.4L Auto), 1: 0.8648514862384631\n",
      "025 Chevrolet Captiva 2010 (2.4L Auto), 5: 0.9226837940291782\n",
      "025 Chevrolet Captiva 2010 (2.4L Auto), 10: 0.9404964902260587\n",
      "027 Chevrolet Cruze 2011 (1.8L Manual), 1: 0.7647982784034113\n",
      "027 Chevrolet Cruze 2011 (1.8L Manual), 5: 0.8331106614564179\n",
      "027 Chevrolet Cruze 2011 (1.8L Manual), 10: 0.8440208423245168\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "f2f7ec7f24822a77954a16386e6454899950191e95b6a4951530c082877018e3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}