{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Training an ARIMA model for FCR estimation to compare its performance with our vehicle-specific metamodels\r\n",
    "#### Ehsan Moradi, Ph.D. Candidate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load required libraries\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "from statsmodels.tsa.arima.model import ARIMA\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.metrics import r2_score\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# General settings\r\n",
    "VEHICLES = (\r\n",
    "    \"019 Hyundai Elantra GT 2019 (2.0L Auto)\",\r\n",
    "    \"025 Chevrolet Captiva 2010 (2.4L Auto)\",\r\n",
    "    \"027 Chevrolet Cruze 2011 (1.8L Manual)\",\r\n",
    ")\r\n",
    "FEATURES = [\"SPD_KH\", \"ACC_MS2\", \"ALT_M\"]\r\n",
    "DEPENDENT = \"FCR_LH\"\r\n",
    "SETTINGS = {\r\n",
    "    \"INPUT_TYPE\": \"ENSEMBLE\",\r\n",
    "    \"INPUT_INDEX\": \"06\",\r\n",
    "    \"OUTPUT_TYPE\": \"ARIMA\",\r\n",
    "    \"OUTPUT_INDEX\": \"COMPARE\",\r\n",
    "}\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Load sample data from Excel to a pandas dataframe\r\n",
    "def load_from_Excel(vehicle, sheet, settings):\r\n",
    "    directory = (\r\n",
    "        \"../../Academia/PhD/Field Experiments/Veepeak/\"\r\n",
    "        + vehicle\r\n",
    "        + \"/Processed/\"\r\n",
    "        + settings[\"INPUT_TYPE\"]\r\n",
    "        + \"/\"\r\n",
    "    )\r\n",
    "    input_file = vehicle + \" - {0} - {1}.xlsx\".format(\r\n",
    "        settings[\"INPUT_TYPE\"], settings[\"INPUT_INDEX\"]\r\n",
    "    )\r\n",
    "    input_path = directory + input_file\r\n",
    "    df = pd.read_excel(input_path, sheet_name=sheet, header=0)\r\n",
    "    return df\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Save the predicted field back to Excel file\r\n",
    "def save_to_excel(df, vehicle, settings):\r\n",
    "    directory = (\r\n",
    "        \"../../Academia/PhD/Field Experiments/Veepeak/\"\r\n",
    "        + vehicle\r\n",
    "        + \"/Processed/\"\r\n",
    "        + settings[\"OUTPUT_TYPE\"]\r\n",
    "        + \"/\"\r\n",
    "    )\r\n",
    "    output_file = vehicle + \" - {0} - {1}.xlsx\".format(\r\n",
    "        settings[\"OUTPUT_TYPE\"], settings[\"OUTPUT_INDEX\"]\r\n",
    "    )\r\n",
    "    output_path = directory + output_file\r\n",
    "    with pd.ExcelWriter(output_path, engine=\"openpyxl\", mode=\"w\") as writer:\r\n",
    "        df.to_excel(writer, header=True, index=None)\r\n",
    "    print(\"{} -> Data is saved to Excel successfully!\".format(vehicle))\r\n",
    "    return None\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Training the ARIMA model and generating out-of-sample predictions\r\n",
    "predictions, observations = {}, {}\r\n",
    "for vehicle in VEHICLES:\r\n",
    "    df = load_from_Excel(vehicle, \"Sheet1\", SETTINGS)\r\n",
    "    # Apply feature scaling\r\n",
    "    scaler_features = StandardScaler().fit(df[FEATURES])\r\n",
    "    scaler_dependent = StandardScaler().fit(df[[DEPENDENT]])\r\n",
    "    df[FEATURES] = scaler_features.transform(df[FEATURES])\r\n",
    "    df[[DEPENDENT]] = scaler_dependent.transform(df[[DEPENDENT]])\r\n",
    "    # Train-Test splitting (70%-30%)\r\n",
    "    split_point = int(.7 * len(df))\r\n",
    "    train = df[:split_point].copy(deep=True)\r\n",
    "    # Train the ARIMA model\r\n",
    "    # The AR order is chosen as 6 (in accordance with our RNN modeling lag order)\r\n",
    "    # As the variables could be considered stationary (they are bounded and trendless), \"difference\" is set to 0.\r\n",
    "    # Moving-average order of 3 is applied.\r\n",
    "    model_l6 = ARIMA(train[DEPENDENT], exog=train[FEATURES], order=(6, 0, 3))\r\n",
    "    fit_l6 = model_l6.fit(method_kwargs={\"warn_convergence\": False})\r\n",
    "    # Out-of-sample prediction\r\n",
    "    predictions[vehicle] = fit_l6.predict(\r\n",
    "        start=len(train), end=len(df) - 1, exog=df[FEATURES][split_point:]).values\r\n",
    "    # Apply inverse scaling\r\n",
    "    df[FEATURES] = scaler_features.inverse_transform(df[FEATURES])\r\n",
    "    predictions[vehicle] = scaler_dependent.inverse_transform(\r\n",
    "        predictions[vehicle])\r\n",
    "    df[[DEPENDENT]] = scaler_dependent.inverse_transform(\r\n",
    "        df[[DEPENDENT]])\r\n",
    "    observations[vehicle] = df[DEPENDENT][split_point:]\r\n",
    "    df.loc[split_point:, \"FCR_LH_PRED_ARIMA\"] = predictions[vehicle]\r\n",
    "    save_to_excel(df, vehicle, SETTINGS)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Time-series plot of ARIMA predictions vs. true observations for a selected time-window\r\n",
    "for vehicle in VEHICLES:\r\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\r\n",
    "    sns.lineplot(x=range(750), y=predictions[vehicle][0:750], color=\"blue\")\r\n",
    "    sns.lineplot(x=range(750), y=observations[vehicle][0:750], color=\"red\")\r\n",
    "    plt.legend(labels=[\"Predictions (AR Order = 6)\", \"True Observations\"])\r\n",
    "    plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Scatter plot to compare ARIMA predictions and true observations\r\n",
    "for vehicle in VEHICLES:\r\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\r\n",
    "    sns.scatterplot(x=observations[vehicle], y=predictions[vehicle])\r\n",
    "    upper_bound = np.max([np.max(observations[vehicle]),\r\n",
    "                         np.max(predictions[vehicle])])\r\n",
    "    plt.xlim(0, upper_bound)\r\n",
    "    plt.ylim(0, upper_bound)\r\n",
    "    plt.xlabel(\"True Observations\")\r\n",
    "    plt.ylabel(\"ARIMA Predictions (AR Order = 6)\")\r\n",
    "    plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate R-squared score\r\n",
    "for vehicle in VEHICLES:\r\n",
    "    print(\"{0}: {1}\".format(vehicle, r2_score(\r\n",
    "        observations[vehicle], predictions[vehicle])))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "f2f7ec7f24822a77954a16386e6454899950191e95b6a4951530c082877018e3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}